{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f067ce0f",
   "metadata": {},
   "source": [
    "# try basic network on mnist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66146b8c",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "27935ed0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-05T12:49:54.019034Z",
     "start_time": "2025-02-05T12:49:45.980132Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train images shape: (60000, 1, 28, 28)\n",
      "Train labels shape: (60000, 10)\n",
      "Test images shape: (10000, 1, 28, 28)\n",
      "Test labels shape: (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import mnist\n",
    "\n",
    "# Load the MNIST dataset\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "\n",
    "# Reshape and add channel dimension\n",
    "train_images = train_images.reshape((60000, 28, 28, 1))  # [B, H, W, C]\n",
    "test_images = test_images.reshape((10000, 28, 28, 1))    # [B, H, W, C]\n",
    "\n",
    "# Convert to [B, C, H, W] format  # [B, C, H, W]\n",
    "\n",
    "# Normalize pixel values to the range [0, 1]\n",
    "train_images = train_images.astype('float32') / 255\n",
    "test_images = test_images.astype('float32') / 255\n",
    "\n",
    "train_images = train_images.transpose(0, 3, 1, 2)\n",
    "test_images = test_images.transpose(0, 3, 1, 2)\n",
    "\n",
    "# Convert labels to one-hot encoding\n",
    "train_labels = tf.keras.utils.to_categorical(train_labels, 10)\n",
    "test_labels = tf.keras.utils.to_categorical(test_labels, 10)\n",
    "\n",
    "# Print shapes\n",
    "print(\"Train images shape:\", train_images.shape)  # Should be (60000, 1, 28, 28)\n",
    "print(\"Train labels shape:\", train_labels.shape)\n",
    "print(\"Test images shape:\", test_images.shape)    # Should be (10000, 1, 28, 28)\n",
    "print(\"Test labels shape:\", test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ba46ad7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(type(train_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fe57f27f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using winograd convolution\n",
      "Using winograd convolution\n",
      "Using im2col convolution\n",
      "Using winograd convolution\n",
      "Using winograd convolution\n",
      "Using im2col convolution\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from core.Models import Model\n",
    "from core.nn import Linear, Conv2d, MaxPool2d , batchnorm2d, Softmax, Relu,Flatten\n",
    "from core.optim import sgd, adam\n",
    "from core.loss import get_loss_fn\n",
    "\n",
    "class ResNetWithResiduals(Model):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        # Initial Convolution\n",
    "        self.conv1 = Conv2d(input_channels=1, output_channels=8, kernel_size=3, stride=1, padding=1, initialize_type='xavier',bias=False)\n",
    "        self.bn1 = batchnorm2d(8)\n",
    "        self.relu1 = Relu()\n",
    "\n",
    "        # Residual Block 1\n",
    "        self.conv2 = Conv2d(input_channels=8, output_channels=16, kernel_size=3, stride=1, padding=1, initialize_type='xavier')\n",
    "        self.bn2 = batchnorm2d(16)\n",
    "        self.relu2 = Relu()\n",
    "        self.res1 = Conv2d(input_channels=8, output_channels=16, kernel_size=1, stride=1, padding=0, initialize_type='xavier')  # Adjust channels\n",
    "        self.max1 = MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        # Residual Block 2\n",
    "        self.conv3 = Conv2d(input_channels=16, output_channels=32, kernel_size=3, stride=1, padding=1, initialize_type='xavier')\n",
    "        self.bn3 = batchnorm2d(32)\n",
    "        self.relu3 = Relu()\n",
    "\n",
    "        self.conv4 = Conv2d(input_channels=32, output_channels=64, kernel_size=3, stride=1, padding=1, initialize_type='xavier')\n",
    "        self.bn4 = batchnorm2d(64)\n",
    "        self.relu4 = Relu()\n",
    "        self.res2 = Conv2d(input_channels=16, output_channels=64, kernel_size=1, stride=1, padding=0, initialize_type='xavier')  # Adjust channels\n",
    "        self.max2 = MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        # Fully Connected Layer\n",
    "        self.flatten = Flatten()\n",
    "        self.linear1 = Linear(64 * 7 * 7, 100, initialize_type='xavier', activation='relu')\n",
    "        self.linear2 = Linear(100, 10, initialize_type='xavier', activation='softmax')\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Initial conv\n",
    "        x1 = self.conv1(x)\n",
    "        x1 = self.bn1(x1)\n",
    "        x1 = self.relu1(x1)\n",
    "\n",
    "        # Residual Block 1\n",
    "        x2 = self.conv2(x1)\n",
    "        x2 = self.bn2(x2)\n",
    "        x2 = self.relu2(x2)\n",
    "        res1 = self.res1(x1)  # Match channel dimensions\n",
    "        x2 = x2 + res1  # Add residual connection\n",
    "        x2 = self.max1(x2)\n",
    "\n",
    "        # Residual Block 2\n",
    "        x3 = self.conv3(x2)\n",
    "        x3 = self.bn3(x3)\n",
    "        x3 = self.relu3(x3)\n",
    "\n",
    "        x4 = self.conv4(x3)\n",
    "        x4 = self.bn4(x4)\n",
    "        x4 = self.relu4(x4)\n",
    "        res2 = self.res2(x2)  # Match channel dimensions\n",
    "        x4 = x4 + res2  # Add residual connection\n",
    "        x4 = self.max2(x4)\n",
    "\n",
    "        # Fully Connected Layer\n",
    "        x4 = self.flatten(x4)\n",
    "        x4 = self.linear1(x4)\n",
    "        x4 = self.linear2(x4)\n",
    "\n",
    "\n",
    "        return x4\n",
    "\n",
    "# Instantiate model\n",
    "model_resnet_residuals = ResNetWithResiduals()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e915d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from core.Datasets import Dataset\n",
    "train_dataset = Dataset(train_images, train_labels, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "039de797",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = adam(model_resnet_residuals.parameters(), learning_rate=0.001)\n",
    "loss_fn = get_loss_fn('categorical_bce')\n",
    "num_epochs = 1\n",
    "def train():\n",
    "    for epoch in range(num_epochs):\n",
    "        train_dataset.reset()  # Reset dataset iterator and reshuffle if needed\n",
    "        epoch_loss = 0.0\n",
    "        num_batches = 0\n",
    "        for X_batch, y_batch in train_dataset:\n",
    "            optimizer.zero_grad()\n",
    "            out = model_resnet_residuals(X_batch)\n",
    "            loss_tensor = loss_fn.sparse_categorical_cross_entropy(y_batch, out)\n",
    "            epoch_loss += loss_tensor.data\n",
    "            num_batches += 1\n",
    "            loss_tensor.backward()\n",
    "            optimizer.step()\n",
    "        avg_loss = epoch_loss / num_batches\n",
    "        \n",
    "        print(f\"Epoch {epoch + 1}/{num_epochs} - Loss: {avg_loss:.4f}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a78f1df",
   "metadata": {},
   "outputs": [],
   "source": [
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fdedf98",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test():\n",
    "    model_resnet_residuals.test()\n",
    "    x = model_resnet_residuals(test_images)\n",
    "    y_pred = x.data\n",
    "    y_pred_classes = np.argmax(y_pred, axis=1, keepdims=True)\n",
    "    y_true_classes = np.argmax(test_labels, axis=1, keepdims=True)  # Assuming test_labels are integers\n",
    "    accuracy = np.mean(y_pred_classes == y_true_classes)\n",
    "    print(f\"Accuracy on test set: {accuracy:.4f}\")\n",
    "\n",
    "test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7ab1d560",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph saved as model_graph.html\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model_resnet_residuals.view_graph(input_data=test_images[:1],filename=\"model_graph\", view=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cf67e63",
   "metadata": {},
   "source": [
    "# Augmentation Module\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af844cec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "\n",
    "# Load CIFAR-10 (only training data for demonstration)\n",
    "(x_train, y_train), _ = cifar10.load_data()\n",
    "\n",
    "# Select a sample image (CIFAR-10 images are 32x32 RGB)\n",
    "sample_img = x_train[0]\n",
    "\n",
    "# Import Compose and all Preprocessing transforms from your package.\n",
    "from Preprocessing.transforms import (\n",
    "    Compose, GaussianBlur, GaussianNoise, Normalize, \n",
    "    RandomAffine, RandomCrop, RandomErasing, RandomHorizontalFlip, \n",
    "    RandomRotation, RandomVerticalFlip, Resize, ToTensor\n",
    ")\n",
    "\n",
    "# Create a dictionary mapping transformation names to their instances.\n",
    "# For demonstration, we force application by setting probabilities to 1.0.\n",
    "aug_transforms = {\n",
    "    \"RandomHorizontalFlip\": RandomHorizontalFlip(p=1.0),\n",
    "    \"RandomVerticalFlip\":   RandomVerticalFlip(p=1.0),\n",
    "    \"RandomCrop\":           RandomCrop((28, 28)),  # Crop to 28x28 (from 32x32)\n",
    "    \"RandomRotation\":       RandomRotation(degrees=30),\n",
    "    \"RandomAffine\":         RandomAffine(degrees=20, translate=(0.1, 0.1), scale=(0.8, 1.2), shear=10),\n",
    "    \"GaussianBlur\":         GaussianBlur(sigma=(0.5, 1.5)),\n",
    "    \"GaussianNoise\":        GaussianNoise(std=(0.01, 0.05)),\n",
    "    \"RandomErasing\":        RandomErasing(p=1.0, scale=(0.02, 0.15), ratio=(0.3, 3.3), value=0)\n",
    "}\n",
    "\n",
    "# Prepare the plot: one row per Preprocessing (each row shows Original and Augmented)\n",
    "n_transforms = len(aug_transforms)\n",
    "fig, axes = plt.subplots(nrows=n_transforms, ncols=2, figsize=(8, n_transforms * 3))\n",
    "\n",
    "for idx, (name, transform) in enumerate(aug_transforms.items()):\n",
    "    # Create a Compose pipeline with a single transform.\n",
    "    pipeline = Compose([transform])\n",
    "    \n",
    "    # Left column: display the original image.\n",
    "    axes[idx, 0].imshow(sample_img)\n",
    "    axes[idx, 0].set_title(\"Original\")\n",
    "    axes[idx, 0].axis(\"off\")\n",
    "    \n",
    "    # Right column: apply the Compose pipeline and display the result.\n",
    "    aug_img = pipeline(sample_img)\n",
    "    if hasattr(aug_img, \"data\"):\n",
    "        aug_img = aug_img.data\n",
    "    axes[idx, 1].imshow(np.clip(aug_img, 0, 255).astype(np.uint8))\n",
    "    axes[idx, 1].set_title(name)\n",
    "    axes[idx, 1].axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe4b0941",
   "metadata": {},
   "source": [
    "# testing pretrained models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "283bf605",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using fft convolution\n",
      "Using winograd convolution\n",
      "Using winograd convolution\n",
      "Using winograd convolution\n",
      "Using winograd convolution\n",
      "Using im2col convolution\n",
      "Using im2col convolution\n",
      "Using winograd convolution\n",
      "Using winograd convolution\n",
      "Using winograd convolution\n",
      "Using im2col convolution\n",
      "Using im2col convolution\n",
      "Using winograd convolution\n",
      "Using winograd convolution\n",
      "Using winograd convolution\n",
      "Using im2col convolution\n",
      "Using im2col convolution\n",
      "Using winograd convolution\n",
      "Using winograd convolution\n",
      "Using winograd convolution\n",
      "Pre-trained ResNet-18 weights loaded from .pth file\n"
     ]
    }
   ],
   "source": [
    "#https://deeplearning.cms.waikato.ac.nz/user-guide/class-maps/IMAGENET/\n",
    "\n",
    "from pretrained.resnet18 import resnet18\n",
    "from core.Models import Model\n",
    "model = resnet18(pretrained=True)\n",
    "model.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "386988b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "from core.tensor import Tensor\n",
    "label = 153\n",
    "imagepath = r\"C:\\Users\\ahmed\\Downloads\\n02085936_Maltese_dog (1).JPEG\"\n",
    "\n",
    "img = Image.open(imagepath)\n",
    "img = img.resize((224, 224))\n",
    "img = np.array(img)\n",
    "img = np.expand_dims(img, axis=0)\n",
    "img = np.transpose(img, (0, 3, 1, 2))  # convert to (batch_size, channels, height, width)\n",
    "img = img / 255.0\n",
    "# img = Tensor(img)\n",
    "\n",
    "# output = model(img)\n",
    "# y_pred = output.data\n",
    "# print(y_pred.shape)\n",
    "# #print top 5 predictions\n",
    "# print(\"Top 5 predictions:\", np.argsort(y_pred[0])[::-1][:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "350c5061",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using winograd convolution\n",
      "Using winograd convolution\n",
      "Using winograd convolution\n",
      "Using winograd convolution\n",
      "Using winograd convolution\n",
      "Using winograd convolution\n",
      "Using winograd convolution\n",
      "Using winograd convolution\n",
      "Using winograd convolution\n",
      "Using winograd convolution\n",
      "Using winograd convolution\n",
      "Using winograd convolution\n",
      "Using winograd convolution\n",
      "Pre-trained VGG-16 weights loaded from .pth file\n"
     ]
    }
   ],
   "source": [
    "from pretrained.vgg16 import VGG16\n",
    "vgg = VGG16(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "066bb24d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 predictions: [153 204 203 155 154]\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "from core.tensor import Tensor\n",
    "label = 153\n",
    "imagepath = r\"C:\\Users\\ahmed\\Downloads\\n02085936_Maltese_dog (1).JPEG\"\n",
    "\n",
    "img = Image.open(imagepath)\n",
    "img = img.resize((224, 224))\n",
    "img = np.array(img)\n",
    "img = np.expand_dims(img, axis=0)\n",
    "img = np.transpose(img, (0, 3, 1, 2))  # convert to (batch_size, channels, height, width)\n",
    "img = img / 255.0\n",
    "img = Tensor(img)\n",
    "\n",
    "output = vgg(img)\n",
    "y_pred = output.data\n",
    "pred_label = np.argmax(y_pred[0], axis=0, keepdims=False)\n",
    "print(\"Top 5 predictions:\", np.argsort(y_pred[0])[::-1][:5])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1db7c01",
   "metadata": {},
   "source": [
    "# new layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fb47e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "from core.Models import Model\n",
    "from core.nn import PositionalEmbedding , PatchEmbedding , LayerNorm,MultiHeadAttention\n",
    "\n",
    "class model(Model):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.patch_embedding = PatchEmbedding()\n",
    "        self.positional_embedding = PositionalEmbedding(self.patch_embedding.n_patches, 768)\n",
    "        self.layer_norm = LayerNorm(768)\n",
    "        self.attention = MultiHeadAttention(768, 8,masked=True)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.patch_embedding(x)\n",
    "        x = self.positional_embedding(x)\n",
    "        x = self.layer_norm(x)\n",
    "        x = self.attention(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5080cb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from core.tensor import Tensor\n",
    "import numpy as np\n",
    "x = Tensor(np.random.rand(1, 3, 224, 224))\n",
    "model = model()\n",
    "output = model(x)\n",
    "output.backward()\n",
    "print(\"Output shape:\", output.shape)\n",
    "print(f\"output gradient shape: {output.grad.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bed0a46",
   "metadata": {},
   "source": [
    "# Autograd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ee497ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from core.tensor import Tensor\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8174fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "x = Tensor(np.random.rand(1))\n",
    "y = -x\n",
    "y.backward()\n",
    "print(y.grad) \n",
    "print(x.grad) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "580a33bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = Tensor([2.0], requires_grad=True)\n",
    "b = Tensor([3.0], requires_grad=True)\n",
    "c = a + b\n",
    "c.backward()\n",
    "\n",
    "print(\"a.grad:\", a.grad)  # should be 1.0\n",
    "print(\"b.grad:\", b.grad)  # should be 1.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18e0d24a",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = Tensor([2.0], requires_grad=True)\n",
    "b = Tensor([3.0], requires_grad=True)\n",
    "c = a * b\n",
    "c.backward()\n",
    "\n",
    "print(\"a.grad:\", a.grad)  # should be b.data = 3.0\n",
    "print(\"b.grad:\", b.grad)  # should be a.data = 2.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cf8d8c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = Tensor([6.0], requires_grad=True)\n",
    "b = Tensor([2.0], requires_grad=True)\n",
    "c = a / b\n",
    "c.backward()\n",
    "\n",
    "print(\"a.grad:\", a.grad)  # should be 1 / b = 0.5\n",
    "print(\"b.grad:\", b.grad)  # should be -a / b^2 = -6 / 4 = -1.5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "284b8186",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = Tensor([5.0], requires_grad=True)\n",
    "b = Tensor([3.0], requires_grad=True)\n",
    "c = a - b\n",
    "c.backward()\n",
    "\n",
    "print(\"a.grad:\", a.grad)  # should be 1\n",
    "print(\"b.grad:\", b.grad)  # should be -1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d6eb06e",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = Tensor([[1.0, 2.0], [3.0, 4.0]], requires_grad=True)\n",
    "c = a.mean()\n",
    "c.backward()\n",
    "\n",
    "print(\"a.grad:\")  # should be a tensor with 0.25 in all positions (1/4)\n",
    "print(a.grad)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdc2b958",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = Tensor([[1.0, 2.0], [3.0, 4.0]], requires_grad=True)\n",
    "c = a.sum()\n",
    "c.backward()\n",
    "\n",
    "print(\"a.grad:\")  # should be all ones\n",
    "print(a.grad)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f6ed04d",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = Tensor([1.0, 2.0, 3.0], requires_grad=True)\n",
    "c = a.std()\n",
    "c.backward()\n",
    "\n",
    "print(\"a.grad:\")  # should compute ∂std/∂x for each element\n",
    "print(a.grad)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beaf41e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = Tensor(1)\n",
    "b = Tensor(2)\n",
    "d = Tensor(3)\n",
    "c = a + b * d\n",
    "c.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "396b72cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "c.view_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9473f62",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68b3c2eb",
   "metadata": {},
   "source": [
    "# test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e76f05c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32664566",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deeplearning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
