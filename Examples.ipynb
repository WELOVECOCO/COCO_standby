{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "66146b8c",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fe57f27f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from core.Models import Model\n",
    "from core.nn import Linear, Conv2d, MaxPool2d , ConvBatchNorm2D,Flatten\n",
    "from core.Function import Relu,Softmax\n",
    "from core.optim import sgd, adam\n",
    "from core.loss import get_loss_fn\n",
    "\n",
    "class ResNetWithResiduals(Model):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = Conv2d(input_channels=1, output_channels=8, kernel_size=3, stride=1, padding=1, initialize_type='xavier',bias=False)\n",
    "        self.bn1 = ConvBatchNorm2D(8)\n",
    "        self.relu1 = Relu()\n",
    "        self.conv2 = Conv2d(input_channels=8, output_channels=16, kernel_size=3, stride=1, padding=1, initialize_type='xavier')\n",
    "        self.bn2 = ConvBatchNorm2D(16)\n",
    "        self.relu2 = Relu()\n",
    "        self.res1 = Conv2d(input_channels=8, output_channels=16, kernel_size=1, stride=1, padding=0, initialize_type='xavier')  # Adjust channels\n",
    "        self.max1 = MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.conv3 = Conv2d(input_channels=16, output_channels=32, kernel_size=3, stride=1, padding=1, initialize_type='xavier')\n",
    "        self.bn3 = ConvBatchNorm2D(32)\n",
    "        self.relu3 = Relu()\n",
    "        self.conv4 = Conv2d(input_channels=32, output_channels=64, kernel_size=3, stride=1, padding=1, initialize_type='xavier')\n",
    "        self.bn4 = ConvBatchNorm2D(64)\n",
    "        self.relu4 = Relu()\n",
    "        self.res2 = Conv2d(input_channels=16, output_channels=64, kernel_size=1, stride=1, padding=0, initialize_type='xavier')  # Adjust channels\n",
    "        self.max2 = MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.flatten = Flatten()\n",
    "        self.linear1 = Linear(64 * 7 * 7, 100, initialize_type='xavier')\n",
    "        self.linear2 = Linear(100, 10, initialize_type='xavier')\n",
    "        self.softmax = Softmax()\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1 = self.conv1(x)\n",
    "        x1 = self.bn1(x1)\n",
    "        x1 = self.relu1(x1)\n",
    "        x2 = self.conv2(x1)\n",
    "        x2 = self.bn2(x2)\n",
    "        x2 = self.relu2(x2)\n",
    "        res1 = self.res1(x1)  # Match channel dimensions\n",
    "        x2 = x2 + res1  # Add residual connection\n",
    "        x2 = self.max1(x2)\n",
    "        x3 = self.conv3(x2)\n",
    "        x3 = self.bn3(x3)\n",
    "        x3 = self.relu3(x3)\n",
    "        x4 = self.conv4(x3)\n",
    "        x4 = self.bn4(x4)\n",
    "        x4 = self.relu4(x4)\n",
    "        res2 = self.res2(x2)  # Match channel dimensions\n",
    "        x4 = x4 + res2  # Add residual connection\n",
    "        x4 = self.max2(x4)\n",
    "        x4 = self.flatten(x4)\n",
    "        x4 = self.linear1(x4)\n",
    "        x4 = self.linear2(x4)\n",
    "        x4 = self.softmax(x4)\n",
    "        return x4\n",
    "\n",
    "# Instantiate model\n",
    "model_resnet_residuals = ResNetWithResiduals()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7e915d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from core.Datasets import mnist\n",
    "train_dataset, test_dataset = mnist(batch_size=32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85de3bed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: (32, 10)\n",
      "Output shape: (32, 10)\n"
     ]
    }
   ],
   "source": [
    "# train_dataset.reset()\n",
    "# x, y = train_dataset.__next__()\n",
    "# print(\"Input shape:\", y.shape)\n",
    "# out = model_resnet_residuals(x)\n",
    "# print(\"Output shape:\", out.shape)\n",
    "# loss = out.sum()\n",
    "# loss.backward(retain_graph=True)\n",
    "# # out.view_graph(filename=\"model_graph\", view=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a33bee51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph saved as graph.html\n"
     ]
    }
   ],
   "source": [
    "# loss.visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecc211be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"Output shape:\", out.shape)  # Should be (batch_size, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "039de797",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = adam(model_resnet_residuals.parameters(), learning_rate=0.001)\n",
    "loss_fn = get_loss_fn('cat_cross_entropy')\n",
    "num_epochs = 1\n",
    "def train():\n",
    "    for epoch in range(num_epochs):\n",
    "        train_dataset.reset()  # Reset dataset iterator and reshuffle if needed\n",
    "        epoch_loss = 0.0\n",
    "        num_batches = 0\n",
    "        for X_batch, y_batch in train_dataset:\n",
    "            optimizer.zero_grad()\n",
    "            out = model_resnet_residuals(X_batch)\n",
    "            loss_tensor = loss_fn(y_batch, out)\n",
    "            epoch_loss += loss_tensor.data\n",
    "            num_batches += 1\n",
    "            loss_tensor.backward()\n",
    "            optimizer.step()\n",
    "        avg_loss = epoch_loss / num_batches\n",
    "        \n",
    "        print(f\"Epoch {epoch + 1}/{num_epochs} - Loss: {avg_loss:.4f}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7a78f1df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1 - Loss: 0.3309\n"
     ]
    }
   ],
   "source": [
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fdedf98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9415714285714286\n"
     ]
    }
   ],
   "source": [
    "def test():\n",
    "    model_resnet_residuals.test()\n",
    "    test_dataset.reset()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for X_batch, y_batch in test_dataset:\n",
    "        out = model_resnet_residuals(X_batch)\n",
    "        predictions = np.argmax(out.data, axis=1)\n",
    "\n",
    "        # Convert one-hot y_batch back to class indices\n",
    "        true_labels = np.argmax(y_batch.data, axis=1)\n",
    "\n",
    "        correct += np.sum(predictions == true_labels)\n",
    "        total += y_batch.data.shape[0]\n",
    "    print(f\"Accuracy: {correct / total}\")\n",
    "\n",
    "\n",
    "test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33eabbd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from core.Function import *\n",
    "\n",
    "lr = LeakyReLU(0.01)\n",
    "x = Tensor.randn(2,3)  # assuming you've implemented randn in your Tensor class\n",
    "x.requires_grad = True\n",
    "y = lr(x)\n",
    "loss = y.sum()          # assuming sum() is implemented\n",
    "loss.backward()\n",
    "print(\"Input gradient shape:\", loss.grad)\n",
    "# Don't access y.grad â€” it's cleared like PyTorch\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cf67e63",
   "metadata": {},
   "source": [
    "# Augmentation Module\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af844cec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "\n",
    "# Load CIFAR-10 (only training data for demonstration)\n",
    "(x_train, y_train), _ = cifar10.load_data()\n",
    "\n",
    "# Select a sample image (CIFAR-10 images are 32x32 RGB)\n",
    "sample_img = x_train[0]\n",
    "\n",
    "# Import Compose and all Preprocessing transforms from your package.\n",
    "from Preprocessing.transforms import (\n",
    "    Compose, GaussianBlur, GaussianNoise, Normalize, \n",
    "    RandomAffine, RandomCrop, RandomErasing, RandomHorizontalFlip, \n",
    "    RandomRotation, RandomVerticalFlip, Resize, ToTensor\n",
    ")\n",
    "\n",
    "# Create a dictionary mapping transformation names to their instances.\n",
    "# For demonstration, we force application by setting probabilities to 1.0.\n",
    "aug_transforms = {\n",
    "    \"RandomHorizontalFlip\": RandomHorizontalFlip(p=1.0),\n",
    "    \"RandomVerticalFlip\":   RandomVerticalFlip(p=1.0),\n",
    "    \"RandomCrop\":           RandomCrop((28, 28)),  # Crop to 28x28 (from 32x32)\n",
    "    \"RandomRotation\":       RandomRotation(degrees=30),\n",
    "    \"RandomAffine\":         RandomAffine(degrees=20, translate=(0.1, 0.1), scale=(0.8, 1.2), shear=10),\n",
    "    \"GaussianBlur\":         GaussianBlur(sigma=(0.5, 1.5)),\n",
    "    \"GaussianNoise\":        GaussianNoise(std=(0.01, 0.05)),\n",
    "    \"RandomErasing\":        RandomErasing(p=1.0, scale=(0.02, 0.15), ratio=(0.3, 3.3), value=0)\n",
    "}\n",
    "\n",
    "# Prepare the plot: one row per Preprocessing (each row shows Original and Augmented)\n",
    "n_transforms = len(aug_transforms)\n",
    "fig, axes = plt.subplots(nrows=n_transforms, ncols=2, figsize=(8, n_transforms * 3))\n",
    "\n",
    "for idx, (name, transform) in enumerate(aug_transforms.items()):\n",
    "    # Create a Compose pipeline with a single transform.\n",
    "    pipeline = Compose([transform])\n",
    "    \n",
    "    # Left column: display the original image.\n",
    "    axes[idx, 0].imshow(sample_img)\n",
    "    axes[idx, 0].set_title(\"Original\")\n",
    "    axes[idx, 0].axis(\"off\")\n",
    "    \n",
    "    # Right column: apply the Compose pipeline and display the result.\n",
    "    aug_img = pipeline(sample_img)\n",
    "    if hasattr(aug_img, \"data\"):\n",
    "        aug_img = aug_img.data\n",
    "    axes[idx, 1].imshow(np.clip(aug_img, 0, 255).astype(np.uint8))\n",
    "    axes[idx, 1].set_title(name)\n",
    "    axes[idx, 1].axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe4b0941",
   "metadata": {},
   "source": [
    "# testing pretrained models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "283bf605",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://deeplearning.cms.waikato.ac.nz/user-guide/class-maps/IMAGENET/\n",
    "\n",
    "from pretrained.resnet18 import resnet18\n",
    "from core.Models import Model\n",
    "model = resnet18(pretrained=True)\n",
    "model.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "386988b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "from core.tensor import Tensor\n",
    "\n",
    "# Correct class label for verification\n",
    "true_label = 153  # Maltese dog\n",
    "\n",
    "# ImageNet mean and std (RGB order)\n",
    "mean = np.array([0.485, 0.456, 0.406])\n",
    "std  = np.array([0.229, 0.224, 0.225])\n",
    "\n",
    "# Load and preprocess the image\n",
    "image_path = r\"C:\\Users\\ahmed\\Downloads\\n02085936_Maltese_dog (1).JPEG\"\n",
    "img = Image.open(image_path).convert('RGB')  # ensure 3 channels\n",
    "img = img.resize((224, 224))\n",
    "\n",
    "# Convert to numpy and normalize\n",
    "img = np.array(img).astype(np.float32) / 255.0  # scale to [0, 1]\n",
    "img = (img - mean) / std  # normalize using ImageNet stats\n",
    "\n",
    "# Convert to (B, C, H, W)\n",
    "img = np.transpose(img, (2, 0, 1))  # from HWC to CHW\n",
    "img = np.expand_dims(img, axis=0)   # add batch dim\n",
    "img = Tensor(img)  # wrap in core.tensor.Tensor\n",
    "\n",
    "# Run inference\n",
    "output = model(img)\n",
    "logits = output.data[0]\n",
    "\n",
    "# Top-5 predictions\n",
    "top5 = np.argsort(logits)[::-1][:5]\n",
    "print(\"Top-5 predicted class indices:\", top5)\n",
    "print(\"Is correct class (153) in Top-5:\", true_label in top5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "350c5061",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pretrained.vgg16 import VGG16\n",
    "vgg = VGG16(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "066bb24d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "from core.tensor import Tensor\n",
    "\n",
    "# Correct class label for verification\n",
    "true_label = 153  # Maltese dog\n",
    "\n",
    "# ImageNet mean and std (RGB order)\n",
    "mean = np.array([0.485, 0.456, 0.406])\n",
    "std  = np.array([0.229, 0.224, 0.225])\n",
    "\n",
    "# Load and preprocess the image\n",
    "image_path = r\"C:\\Users\\ahmed\\Downloads\\n02085936_Maltese_dog (1).JPEG\"\n",
    "img = Image.open(image_path).convert('RGB')  # ensure 3 channels\n",
    "img = img.resize((224, 224))\n",
    "\n",
    "# Convert to numpy and normalize\n",
    "img = np.array(img).astype(np.float32) / 255.0  # scale to [0, 1]\n",
    "img = (img - mean) / std  # normalize using ImageNet stats\n",
    "\n",
    "# Convert to (B, C, H, W)\n",
    "img = np.transpose(img, (2, 0, 1))  # from HWC to CHW\n",
    "img = np.expand_dims(img, axis=0)   # add batch dim\n",
    "img = Tensor(img)  # wrap in core.tensor.Tensor\n",
    "\n",
    "# Run inference\n",
    "output = vgg(img)\n",
    "logits = output.data[0]\n",
    "\n",
    "# Top-5 predictions\n",
    "top5 = np.argsort(logits)[::-1][:5]\n",
    "print(\"Top-5 predicted class indices:\", top5)\n",
    "print(\"Is correct class (153) in Top-5:\", true_label in top5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1db7c01",
   "metadata": {},
   "source": [
    "# new layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fb47e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "from core.Models import Model\n",
    "from core.nn import PositionalEmbedding , PatchEmbedding , LayerNorm,MultiHeadAttention\n",
    "\n",
    "class model(Model):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.patch_embedding = PatchEmbedding()\n",
    "        self.positional_embedding = PositionalEmbedding(self.patch_embedding.n_patches, 768)\n",
    "        self.layer_norm = LayerNorm(768)\n",
    "        # self.attention = MultiHeadAttention(768, 8,masked=True)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.patch_embedding(x)\n",
    "        x = self.positional_embedding(x)\n",
    "        x = self.layer_norm(x)\n",
    "        # x = self.attention(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5080cb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from core.tensor import Tensor\n",
    "import numpy as np\n",
    "x = Tensor(np.random.rand(1, 3, 224, 224))\n",
    "model = model()\n",
    "output = model(x)\n",
    "output.backward()\n",
    "print(\"Output shape:\", output.shape)\n",
    "print(f\"output gradient shape: {output.grad.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71c7a7b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "output.view_graph(filename=\"model_graph\", view=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bed0a46",
   "metadata": {},
   "source": [
    "# Autograd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ee497ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from core.new_tensor import Tensor\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8174fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#numpy array of size 2x2\n",
    "x_np = np.array([[1,1],[1,1]])\n",
    "x = Tensor(x_np,requires_grad=True)\n",
    "z = x + 2\n",
    "f = x * z\n",
    "print(f)\n",
    "# print(f._grad_fn.next_functions)\n",
    "f.backward(retain_graph=True)\n",
    "# print(f._engine.graph_nodes)\n",
    "print(x.grad)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ce49152",
   "metadata": {},
   "outputs": [],
   "source": [
    "f.visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afc6c775",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = Tensor(np.ones((2,2)),requires_grad=True)\n",
    "\n",
    "# x is used twice in the graph\n",
    "y1 = x + 1\n",
    "y2 = x * 3\n",
    "z = y1 + y2  # final output\n",
    "\n",
    "z.backward(retain_graph=True)\n",
    "print(\"x.grad:\")\n",
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "022e3453",
   "metadata": {},
   "outputs": [],
   "source": [
    "z.visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72a9c544",
   "metadata": {},
   "outputs": [],
   "source": [
    "for node in z._engine.graph_nodes:\n",
    "    print(node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da585d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "x = torch.ones((2, 2), requires_grad=True)\n",
    "\n",
    "y1 = x + 1        # y1 = x + 1 â†’ dy1/dx = 1\n",
    "y2 = x * 3        # y2 = x * 3 â†’ dy2/dx = 3\n",
    "\n",
    "z = y1 + y2       # z = (x + 1) + (x * 3) = x + 1 + 3x = 4x + 1\n",
    "\n",
    "z.backward(torch.ones_like(z))\n",
    "\n",
    "print(\"x.grad:\")\n",
    "print(x.grad)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18e0d24a",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = Tensor([2.0], requires_grad=True)\n",
    "b = Tensor([3.0], requires_grad=True)\n",
    "c = a * b\n",
    "c.backward()\n",
    "\n",
    "print(\"a.grad:\", a.grad)  # should be b.data = 3.0\n",
    "print(\"b.grad:\", b.grad)  # should be a.data = 2.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cf8d8c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = Tensor([6.0], requires_grad=True)\n",
    "b = Tensor([2.0], requires_grad=True)\n",
    "c = a / 2\n",
    "print(c)\n",
    "c.backward()\n",
    "\n",
    "print(\"a.grad:\", a.grad)  # should be 1 / b = 0.5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "284b8186",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = Tensor([5.0], requires_grad=True)\n",
    "b = Tensor([3.0], requires_grad=True)\n",
    "c = a - b\n",
    "c.backward()\n",
    "\n",
    "print(\"a.grad:\", a.grad)  # should be 1\n",
    "print(\"b.grad:\", b.grad)  # should be -1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d6eb06e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from core.new_tensor import Tensor\n",
    "import numpy as np\n",
    "\n",
    "a = Tensor([[1.0, 2.0], [3.0, 4.0]], requires_grad=True)\n",
    "c = a.mean()\n",
    "c.backward(retain_graph=True)\n",
    "print(\"a.grad:\")  #\n",
    "print(a.grad)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdc2b958",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = Tensor([[1.0, 2.0], [3.0, 4.0]], requires_grad=True)\n",
    "c = a.sum()\n",
    "c.backward()\n",
    "\n",
    "print(\"a.grad:\")  # should be all ones\n",
    "print(a.grad)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f6ed04d",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = Tensor([1.0, 2.0, 3.0], requires_grad=True)\n",
    "c = a.std()\n",
    "c.backward()\n",
    "\n",
    "print(\"a.grad:\")  # should compute âˆ‚std/âˆ‚x for each element\n",
    "print(a.grad)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfecfa04",
   "metadata": {},
   "outputs": [],
   "source": [
    "from core.new_tensor import Tensor\n",
    "a = Tensor(2.0, requires_grad=True)\n",
    "b = Tensor(3.0, requires_grad=True)\n",
    "c = Tensor(4.0, requires_grad=True)\n",
    "\n",
    "z = a*b + a*c\n",
    "z.backward()\n",
    "\n",
    "print(\"dz/da =\", a.grad)  # expected b + c = 3 + 4 = 7\n",
    "print(\"dz/db =\", b.grad)  # expected a = 2\n",
    "print(\"dz/dc =\", c.grad)  # expected a = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07252561",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deeplearning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
