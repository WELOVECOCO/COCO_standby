{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f067ce0f",
   "metadata": {},
   "source": [
    "# try basic network on mnist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66146b8c",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27935ed0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-05T12:49:54.019034Z",
     "start_time": "2025-02-05T12:49:45.980132Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import mnist\n",
    "\n",
    "# Load the MNIST dataset\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "\n",
    "# Reshape and add channel dimension\n",
    "train_images = train_images.reshape((60000, 28, 28, 1))  # [B, H, W, C]\n",
    "test_images = test_images.reshape((10000, 28, 28, 1))    # [B, H, W, C]\n",
    "\n",
    "# Convert to [B, C, H, W] format  # [B, C, H, W]\n",
    "\n",
    "# Normalize pixel values to the range [0, 1]\n",
    "train_images = train_images.astype('float32') / 255\n",
    "test_images = test_images.astype('float32') / 255\n",
    "\n",
    "train_images = train_images.transpose(0, 3, 1, 2)\n",
    "test_images = test_images.transpose(0, 3, 1, 2)\n",
    "\n",
    "# Convert labels to one-hot encoding\n",
    "train_labels = tf.keras.utils.to_categorical(train_labels, 10)\n",
    "test_labels = tf.keras.utils.to_categorical(test_labels, 10)\n",
    "\n",
    "# Print shapes\n",
    "print(\"Train images shape:\", train_images.shape)  # Should be (60000, 1, 28, 28)\n",
    "print(\"Train labels shape:\", train_labels.shape)\n",
    "print(\"Test images shape:\", test_images.shape)    # Should be (10000, 1, 28, 28)\n",
    "print(\"Test labels shape:\", test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba46ad7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(train_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe57f27f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from core.Models import Model\n",
    "from core.nn import Linear, Conv2d, MaxPool2d , batchnorm2d, Softmax, Relu,Flatten\n",
    "from core.optim import sgd, adam\n",
    "from core.loss import get_loss_fn\n",
    "\n",
    "class ResNetWithResiduals(Model):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = Conv2d(input_channels=1, output_channels=8, kernel_size=3, stride=1, padding=1, initialize_type='xavier',bias=False)\n",
    "        self.bn1 = batchnorm2d(8)\n",
    "        self.relu1 = Relu()\n",
    "        self.conv2 = Conv2d(input_channels=8, output_channels=16, kernel_size=3, stride=1, padding=1, initialize_type='xavier')\n",
    "        self.bn2 = batchnorm2d(16)\n",
    "        self.relu2 = Relu()\n",
    "        self.res1 = Conv2d(input_channels=8, output_channels=16, kernel_size=1, stride=1, padding=0, initialize_type='xavier')  # Adjust channels\n",
    "        self.max1 = MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.conv3 = Conv2d(input_channels=16, output_channels=32, kernel_size=3, stride=1, padding=1, initialize_type='xavier')\n",
    "        self.bn3 = batchnorm2d(32)\n",
    "        self.relu3 = Relu()\n",
    "        self.conv4 = Conv2d(input_channels=32, output_channels=64, kernel_size=3, stride=1, padding=1, initialize_type='xavier')\n",
    "        self.bn4 = batchnorm2d(64)\n",
    "        self.relu4 = Relu()\n",
    "        self.res2 = Conv2d(input_channels=16, output_channels=64, kernel_size=1, stride=1, padding=0, initialize_type='xavier')  # Adjust channels\n",
    "        self.max2 = MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.flatten = Flatten()\n",
    "        self.linear1 = Linear(64 * 7 * 7, 100, initialize_type='xavier', activation='relu')\n",
    "        self.linear2 = Linear(100, 10, initialize_type='xavier', activation='softmax')\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1 = self.conv1(x)\n",
    "        x1 = self.bn1(x1)\n",
    "        x1 = self.relu1(x1)\n",
    "        x2 = self.conv2(x1)\n",
    "        x2 = self.bn2(x2)\n",
    "        x2 = self.relu2(x2)\n",
    "        res1 = self.res1(x1)  # Match channel dimensions\n",
    "        x2 = x2 + res1  # Add residual connection\n",
    "        x2 = self.max1(x2)\n",
    "        x3 = self.conv3(x2)\n",
    "        x3 = self.bn3(x3)\n",
    "        x3 = self.relu3(x3)\n",
    "        x4 = self.conv4(x3)\n",
    "        x4 = self.bn4(x4)\n",
    "        x4 = self.relu4(x4)\n",
    "        res2 = self.res2(x2)  # Match channel dimensions\n",
    "        x4 = x4 + res2  # Add residual connection\n",
    "        x4 = self.max2(x4)\n",
    "        x4 = self.flatten(x4)\n",
    "        x4 = self.linear1(x4)\n",
    "        x4 = self.linear2(x4)\n",
    "        return x4\n",
    "\n",
    "# Instantiate model\n",
    "model_resnet_residuals = ResNetWithResiduals()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e915d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from core.Datasets import Dataset\n",
    "train_dataset = Dataset(train_images, train_labels, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85de3bed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#feed one example to check the model\n",
    "train_dataset.reset()\n",
    "x, y = train_dataset.__next__()\n",
    "out = model_resnet_residuals(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecc211be",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Output shape:\", out.shape)  # Should be (batch_size, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "570de133",
   "metadata": {},
   "outputs": [],
   "source": [
    "out.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32910b7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "out.view_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "039de797",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = adam(model_resnet_residuals.parameters(), learning_rate=0.001)\n",
    "loss_fn = get_loss_fn('categorical_bce')\n",
    "num_epochs = 1\n",
    "def train():\n",
    "    for epoch in range(num_epochs):\n",
    "        train_dataset.reset()  # Reset dataset iterator and reshuffle if needed\n",
    "        epoch_loss = 0.0\n",
    "        num_batches = 0\n",
    "        for X_batch, y_batch in train_dataset:\n",
    "            optimizer.zero_grad()\n",
    "            out = model_resnet_residuals(X_batch)\n",
    "            loss_tensor = loss_fn.sparse_categorical_cross_entropy(y_batch, out)\n",
    "            epoch_loss += loss_tensor.data\n",
    "            num_batches += 1\n",
    "            loss_tensor.backward()\n",
    "            optimizer.step()\n",
    "        avg_loss = epoch_loss / num_batches\n",
    "        \n",
    "        print(f\"Epoch {epoch + 1}/{num_epochs} - Loss: {avg_loss:.4f}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a78f1df",
   "metadata": {},
   "outputs": [],
   "source": [
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fdedf98",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test():\n",
    "    model_resnet_residuals.test()\n",
    "    x = model_resnet_residuals(test_images)\n",
    "    y_pred = x.data\n",
    "    y_pred_classes = np.argmax(y_pred, axis=1, keepdims=True)\n",
    "    y_true_classes = np.argmax(test_labels, axis=1, keepdims=True)  # Assuming test_labels are integers\n",
    "    accuracy = np.mean(y_pred_classes == y_true_classes)\n",
    "    print(f\"Accuracy on test set: {accuracy:.4f}\")\n",
    "\n",
    "test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ab1d560",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model_resnet_residuals.view_graph(input_data=test_images[:1],filename=\"model_graph\", view=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cf67e63",
   "metadata": {},
   "source": [
    "# Augmentation Module\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af844cec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "\n",
    "# Load CIFAR-10 (only training data for demonstration)\n",
    "(x_train, y_train), _ = cifar10.load_data()\n",
    "\n",
    "# Select a sample image (CIFAR-10 images are 32x32 RGB)\n",
    "sample_img = x_train[0]\n",
    "\n",
    "# Import Compose and all Preprocessing transforms from your package.\n",
    "from Preprocessing.transforms import (\n",
    "    Compose, GaussianBlur, GaussianNoise, Normalize, \n",
    "    RandomAffine, RandomCrop, RandomErasing, RandomHorizontalFlip, \n",
    "    RandomRotation, RandomVerticalFlip, Resize, ToTensor\n",
    ")\n",
    "\n",
    "# Create a dictionary mapping transformation names to their instances.\n",
    "# For demonstration, we force application by setting probabilities to 1.0.\n",
    "aug_transforms = {\n",
    "    \"RandomHorizontalFlip\": RandomHorizontalFlip(p=1.0),\n",
    "    \"RandomVerticalFlip\":   RandomVerticalFlip(p=1.0),\n",
    "    \"RandomCrop\":           RandomCrop((28, 28)),  # Crop to 28x28 (from 32x32)\n",
    "    \"RandomRotation\":       RandomRotation(degrees=30),\n",
    "    \"RandomAffine\":         RandomAffine(degrees=20, translate=(0.1, 0.1), scale=(0.8, 1.2), shear=10),\n",
    "    \"GaussianBlur\":         GaussianBlur(sigma=(0.5, 1.5)),\n",
    "    \"GaussianNoise\":        GaussianNoise(std=(0.01, 0.05)),\n",
    "    \"RandomErasing\":        RandomErasing(p=1.0, scale=(0.02, 0.15), ratio=(0.3, 3.3), value=0)\n",
    "}\n",
    "\n",
    "# Prepare the plot: one row per Preprocessing (each row shows Original and Augmented)\n",
    "n_transforms = len(aug_transforms)\n",
    "fig, axes = plt.subplots(nrows=n_transforms, ncols=2, figsize=(8, n_transforms * 3))\n",
    "\n",
    "for idx, (name, transform) in enumerate(aug_transforms.items()):\n",
    "    # Create a Compose pipeline with a single transform.\n",
    "    pipeline = Compose([transform])\n",
    "    \n",
    "    # Left column: display the original image.\n",
    "    axes[idx, 0].imshow(sample_img)\n",
    "    axes[idx, 0].set_title(\"Original\")\n",
    "    axes[idx, 0].axis(\"off\")\n",
    "    \n",
    "    # Right column: apply the Compose pipeline and display the result.\n",
    "    aug_img = pipeline(sample_img)\n",
    "    if hasattr(aug_img, \"data\"):\n",
    "        aug_img = aug_img.data\n",
    "    axes[idx, 1].imshow(np.clip(aug_img, 0, 255).astype(np.uint8))\n",
    "    axes[idx, 1].set_title(name)\n",
    "    axes[idx, 1].axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe4b0941",
   "metadata": {},
   "source": [
    "# testing pretrained models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "283bf605",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://deeplearning.cms.waikato.ac.nz/user-guide/class-maps/IMAGENET/\n",
    "\n",
    "from pretrained.resnet18 import resnet18\n",
    "from core.Models import Model\n",
    "model = resnet18(pretrained=True)\n",
    "model.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "386988b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "from core.tensor import Tensor\n",
    "label = 153\n",
    "imagepath = r\"C:\\Users\\ahmed\\Downloads\\n02085936_Maltese_dog (1).JPEG\"\n",
    "\n",
    "img = Image.open(imagepath)\n",
    "img = img.resize((224, 224))\n",
    "img = np.array(img)\n",
    "img = np.expand_dims(img, axis=0)\n",
    "img = np.transpose(img, (0, 3, 1, 2))  # convert to (batch_size, channels, height, width)\n",
    "img = img / 255.0\n",
    "# img = Tensor(img)\n",
    "\n",
    "# output = model(img)\n",
    "# y_pred = output.data\n",
    "# print(y_pred.shape)\n",
    "# #print top 5 predictions\n",
    "# print(\"Top 5 predictions:\", np.argsort(y_pred[0])[::-1][:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "350c5061",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pretrained.vgg16 import VGG16\n",
    "vgg = VGG16(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "066bb24d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "from core.tensor import Tensor\n",
    "label = 153\n",
    "imagepath = r\"C:\\Users\\ahmed\\Downloads\\n02085936_Maltese_dog (1).JPEG\"\n",
    "\n",
    "img = Image.open(imagepath)\n",
    "img = img.resize((224, 224))\n",
    "img = np.array(img)\n",
    "img = np.expand_dims(img, axis=0)\n",
    "img = np.transpose(img, (0, 3, 1, 2))  # convert to (batch_size, channels, height, width)\n",
    "img = img / 255.0\n",
    "img = Tensor(img)\n",
    "\n",
    "output = vgg(img)\n",
    "y_pred = output.data\n",
    "pred_label = np.argmax(y_pred[0], axis=0, keepdims=False)\n",
    "print(\"Top 5 predictions:\", np.argsort(y_pred[0])[::-1][:5])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1db7c01",
   "metadata": {},
   "source": [
    "# new layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fb47e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "from core.Models import Model\n",
    "from core.nn import PositionalEmbedding , PatchEmbedding , LayerNorm,MultiHeadAttention\n",
    "\n",
    "class model(Model):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.patch_embedding = PatchEmbedding()\n",
    "        self.positional_embedding = PositionalEmbedding(self.patch_embedding.n_patches, 768)\n",
    "        self.layer_norm = LayerNorm(768)\n",
    "        # self.attention = MultiHeadAttention(768, 8,masked=True)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.patch_embedding(x)\n",
    "        x = self.positional_embedding(x)\n",
    "        x = self.layer_norm(x)\n",
    "        # x = self.attention(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5080cb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from core.tensor import Tensor\n",
    "import numpy as np\n",
    "x = Tensor(np.random.rand(1, 3, 224, 224))\n",
    "model = model()\n",
    "output = model(x)\n",
    "output.backward()\n",
    "print(\"Output shape:\", output.shape)\n",
    "print(f\"output gradient shape: {output.grad.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71c7a7b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "output.view_graph(filename=\"model_graph\", view=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bed0a46",
   "metadata": {},
   "source": [
    "# Autograd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ee497ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from core.tensor import Tensor\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8174fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "x = Tensor(np.random.rand(1))\n",
    "y = -x\n",
    "y.backward()\n",
    "print(y.grad) \n",
    "print(x.grad) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "580a33bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = Tensor([2.0], requires_grad=True)\n",
    "b = Tensor([3.0], requires_grad=True)\n",
    "c = a + b\n",
    "c.backward()\n",
    "\n",
    "print(\"a.grad:\", a.grad)  # should be 1.0\n",
    "print(\"b.grad:\", b.grad)  # should be 1.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18e0d24a",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = Tensor([2.0], requires_grad=True)\n",
    "b = Tensor([3.0], requires_grad=True)\n",
    "c = a * b\n",
    "c.backward()\n",
    "\n",
    "print(\"a.grad:\", a.grad)  # should be b.data = 3.0\n",
    "print(\"b.grad:\", b.grad)  # should be a.data = 2.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cf8d8c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = Tensor([6.0], requires_grad=True)\n",
    "b = Tensor([2.0], requires_grad=True)\n",
    "c = a / b\n",
    "c.backward()\n",
    "\n",
    "print(\"a.grad:\", a.grad)  # should be 1 / b = 0.5\n",
    "print(\"b.grad:\", b.grad)  # should be -a / b^2 = -6 / 4 = -1.5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "284b8186",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = Tensor([5.0], requires_grad=True)\n",
    "b = Tensor([3.0], requires_grad=True)\n",
    "c = a - b\n",
    "c.backward()\n",
    "\n",
    "print(\"a.grad:\", a.grad)  # should be 1\n",
    "print(\"b.grad:\", b.grad)  # should be -1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d6eb06e",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = Tensor([[1.0, 2.0], [3.0, 4.0]], requires_grad=True)\n",
    "c = a.mean()\n",
    "c.backward()\n",
    "\n",
    "print(\"a.grad:\")  # should be a tensor with 0.25 in all positions (1/4)\n",
    "print(a.grad)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdc2b958",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = Tensor([[1.0, 2.0], [3.0, 4.0]], requires_grad=True)\n",
    "c = a.sum()\n",
    "c.backward()\n",
    "\n",
    "print(\"a.grad:\")  # should be all ones\n",
    "print(a.grad)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f6ed04d",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = Tensor([1.0, 2.0, 3.0], requires_grad=True)\n",
    "c = a.std()\n",
    "c.backward()\n",
    "\n",
    "print(\"a.grad:\")  # should compute ∂std/∂x for each element\n",
    "print(a.grad)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beaf41e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from core.tensor import Tensor\n",
    "a = Tensor(1)\n",
    "b = Tensor(2)\n",
    "c = a + b \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cf093bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "c.backward()\n",
    "# c.backward()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f10e1715",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"a.grad:\", a.grad)  # should be 1\n",
    "print(\"c.grad:\", c.grad)  # should be None, as c is not a leaf node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "396b72cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "c.view_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9473f62",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d531f217",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "68b3c2eb",
   "metadata": {},
   "source": [
    "# test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "929fa92d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from core.tensor import Tensor\n",
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "x = Tensor(np.random.rand(32, 64, 224, 224), requires_grad=True)\n",
    "kernel = Tensor(np.random.rand(128, 64, 3, 3))\n",
    "\n",
    "h_out = 224 - 3 + 1\n",
    "w_out = 224 - 3 + 1\n",
    "\n",
    "batch_stride, channel_stride, height_stride, width_stride = x.data.strides\n",
    "\n",
    "# Fixed shape to match the actual tensor dimensions\n",
    "shape = (32, 64, h_out, w_out, 3, 3)\n",
    "strides = (\n",
    "    batch_stride,\n",
    "    channel_stride,\n",
    "    height_stride,\n",
    "    width_stride,\n",
    "    height_stride,\n",
    "    width_stride,\n",
    ")\n",
    "\n",
    "patches = x.as_strided(shape, strides)\n",
    "# shape: (32, 64, 222, 222, 3, 3)\n",
    "\n",
    "# Fixed reshape dimensions\n",
    "col_matrix = patches.transpose(0, 2, 3, 1, 4, 5).reshape(32 * h_out * w_out, 64 * 3 * 3)\n",
    "# (N*H_out*W_out, C*KH*KW)\n",
    "\n",
    "# Fixed kernel reshape dimensions\n",
    "reshaped_kernel = kernel.reshape(128, 64 * 3 * 3).T\n",
    "# (C*KH*KW, num_filters) = (576, 128)\n",
    "\n",
    "out = col_matrix @ reshaped_kernel\n",
    "# (N*H_out*W_out, num_filters)\n",
    "\n",
    "output = out.reshape(32, h_out, w_out, 128).transpose(0, 3, 1, 2)\n",
    "# (N, num_filters, H_out, W_out)\n",
    "\n",
    "end_time = time.time()\n",
    "total_time = end_time - start_time\n",
    "\n",
    "print(\"Time taken for convolution:\", total_time, \"seconds\")\n",
    "print(\"Output shape:\", output.shape)  # (32, 128, 222, 222)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "754344d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cupy as cp\n",
    "import time\n",
    "\n",
    "# Start timing\n",
    "start_time = time.time()\n",
    "\n",
    "# Create tensors on GPU\n",
    "x = cp.random.rand(32, 64, 224, 224)\n",
    "kernel = cp.random.rand(128, 64, 3, 3)\n",
    "\n",
    "# Calculate output dimensions\n",
    "h_out = 224 - 3 + 1\n",
    "w_out = 224 - 3 + 1\n",
    "\n",
    "# Get strides from the CuPy array\n",
    "batch_stride, channel_stride, height_stride, width_stride = x.strides\n",
    "\n",
    "# Define shape and strides for as_strided\n",
    "shape = (32, 64, h_out, w_out, 3, 3)\n",
    "strides = (\n",
    "    batch_stride,\n",
    "    channel_stride,\n",
    "    height_stride,\n",
    "    width_stride,\n",
    "    height_stride,\n",
    "    width_stride,\n",
    ")\n",
    "\n",
    "# Create patches using as_strided\n",
    "patches = cp.lib.stride_tricks.as_strided(x, shape, strides)\n",
    "# shape: (32, 64, 222, 222, 3, 3)\n",
    "\n",
    "# Reshape to column matrix\n",
    "col_matrix = patches.transpose(0, 2, 3, 1, 4, 5).reshape(32 * h_out * w_out, 64 * 3 * 3)\n",
    "# (N*H_out*W_out, C*KH*KW)\n",
    "\n",
    "# Reshape kernel\n",
    "reshaped_kernel = kernel.reshape(128, 64 * 3 * 3).T\n",
    "# (C*KH*KW, num_filters) = (576, 128)\n",
    "\n",
    "# Matrix multiplication\n",
    "out = col_matrix @ reshaped_kernel\n",
    "# (N*H_out*W_out, num_filters)\n",
    "\n",
    "# Reshape output\n",
    "output = out.reshape(32, h_out, w_out, 128).transpose(0, 3, 1, 2)\n",
    "# (N, num_filters, H_out, W_out)\n",
    "\n",
    "# Synchronize GPU to ensure all operations are complete\n",
    "cp.cuda.Stream.null.synchronize()\n",
    "\n",
    "total_time = time.time() - start_time\n",
    "\n",
    "print(\"Output shape:\", output.shape)  # (32, 128, 222, 222)\n",
    "print(f\"Total execution time: {total_time:.4f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22219cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "output.backward()\n",
    "print(f\"out grad shape: {output.grad.shape}\")\n",
    "print(f\"y grad shape: {kernel.grad.shape}\")\n",
    "print(f\"x grad shape: {x.grad.shape}\")\n",
    "output.view_graph(filename=\"conv_graph\", view=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7074ce29",
   "metadata": {},
   "outputs": [],
   "source": [
    "from core.tensor import Tensor\n",
    "import numpy as np\n",
    "from core.nn import Conv2d\n",
    "\n",
    "x = Tensor(np.random.rand(1, 3, 224, 224), requires_grad=True)\n",
    "kernel = Tensor(np.random.rand(64, 3, 3, 3), requires_grad=True)\n",
    "conv = Conv2d(input_channels=3,output_channels= 64, kernel_size=3,bias=True,padding=1)\n",
    "y = conv(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfdd0fe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Output shape:\", y.shape)  # (1, 64, 222, 222)\n",
    "y.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57b6a728",
   "metadata": {},
   "outputs": [],
   "source": [
    "y.view_graph(filename=\"conv_graph\", view=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b53151a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "from core.tensor import Tensor\n",
    "\n",
    "def convolution_im2col(x, kernel, device='cpu'):\n",
    "    \"\"\"\n",
    "    Perform convolution using im2col approach\n",
    "    \"\"\"\n",
    "    # Move tensors to specified device\n",
    "    if device == 'gpu':\n",
    "        x = x.cuda()\n",
    "        kernel = kernel.cuda()\n",
    "    else:\n",
    "        x = x.cpu()\n",
    "        kernel = kernel.cpu()\n",
    "    \n",
    "    # Calculate output dimensions\n",
    "    h_out = x.shape[2] - kernel.shape[2] + 1\n",
    "    w_out = x.shape[3] - kernel.shape[3] + 1\n",
    "    \n",
    "    # Get strides for the input tensor\n",
    "    batch_stride, channel_stride, height_stride, width_stride = x.data.strides\n",
    "    \n",
    "    # Create sliding window view using as_strided\n",
    "    shape = (x.shape[0], x.shape[1], h_out, w_out, kernel.shape[2], kernel.shape[3])\n",
    "    strides = (\n",
    "        batch_stride,\n",
    "        channel_stride,\n",
    "        height_stride,\n",
    "        width_stride,\n",
    "        height_stride,\n",
    "        width_stride,\n",
    "    )\n",
    "    \n",
    "    patches = x.as_strided(shape, strides)\n",
    "    \n",
    "    # Reshape patches to column matrix (im2col)\n",
    "    # shape: (N*H_out*W_out, C*KH*KW)\n",
    "    col_matrix = patches.transpose(0, 2, 3, 1, 4, 5).reshape(\n",
    "        x.shape[0] * h_out * w_out, \n",
    "        x.shape[1] * kernel.shape[2] * kernel.shape[3]\n",
    "    )\n",
    "    \n",
    "    # Reshape kernel to (C*KH*KW, num_filters)\n",
    "    reshaped_kernel = kernel.reshape(kernel.shape[0], -1).T\n",
    "    \n",
    "    # Matrix multiplication (this is where the convolution happens)\n",
    "    out = col_matrix @ reshaped_kernel\n",
    "    \n",
    "    # Reshape back to proper output format\n",
    "    output = out.reshape(x.shape[0], h_out, w_out, kernel.shape[0]).transpose(0, 3, 1, 2)\n",
    "    \n",
    "    return output\n",
    "\n",
    "def benchmark_convolution():\n",
    "    \"\"\"\n",
    "    Benchmark convolution on CPU vs GPU\n",
    "    \"\"\"\n",
    "    print(\"=== Convolution Benchmark: CPU vs GPU ===\\n\")\n",
    "    \n",
    "    # Create input data\n",
    "    print(\"Creating input tensors...\")\n",
    "    x_data = np.random.rand(1, 3, 224, 224).astype(np.float32)\n",
    "    kernel_data = np.random.rand(64, 3, 3, 3).astype(np.float32)\n",
    "    \n",
    "    # Create tensors\n",
    "    x_cpu = Tensor(x_data, requires_grad=True, device='cpu')\n",
    "    kernel_cpu = Tensor(kernel_data, requires_grad=False, device='cpu')\n",
    "    \n",
    "    x_gpu = Tensor(x_data, requires_grad=True, device='gpu')\n",
    "    kernel_gpu = Tensor(kernel_data, requires_grad=False, device='gpu')\n",
    "    \n",
    "    print(f\"Input shape: {x_cpu.shape}\")\n",
    "    print(f\"Kernel shape: {kernel_cpu.shape}\")\n",
    "    print(f\"Expected output shape: (1, 64, 222, 222)\\n\")\n",
    "    \n",
    "    # Warm up runs (important for GPU)\n",
    "    print(\"Performing warm-up runs...\")\n",
    "    try:\n",
    "        _ = convolution_im2col(x_gpu, kernel_gpu, device='gpu')\n",
    "        _ = convolution_im2col(x_cpu, kernel_cpu, device='cpu')\n",
    "        print(\"Warm-up completed.\\n\")\n",
    "    except Exception as e:\n",
    "        print(f\"GPU warm-up failed: {e}\")\n",
    "        print(\"Continuing with CPU-only benchmark.\\n\")\n",
    "    \n",
    "    # CPU Benchmark\n",
    "    print(\"=== CPU Benchmark ===\")\n",
    "    cpu_times = []\n",
    "    num_runs = 5\n",
    "    \n",
    "    for i in range(num_runs):\n",
    "        start_time = time.time()\n",
    "        output_cpu = convolution_im2col(x_cpu, kernel_cpu, device='cpu')\n",
    "        end_time = time.time()\n",
    "        \n",
    "        cpu_time = end_time - start_time\n",
    "        cpu_times.append(cpu_time)\n",
    "        print(f\"Run {i+1}: {cpu_time:.4f} seconds\")\n",
    "    \n",
    "    avg_cpu_time = np.mean(cpu_times)\n",
    "    std_cpu_time = np.std(cpu_times)\n",
    "    print(f\"CPU Average: {avg_cpu_time:.4f} ± {std_cpu_time:.4f} seconds\")\n",
    "    print(f\"CPU Output shape: {output_cpu.shape}\\n\")\n",
    "    \n",
    "    # GPU Benchmark\n",
    "    print(\"=== GPU Benchmark ===\")\n",
    "    try:\n",
    "        gpu_times = []\n",
    "        \n",
    "        for i in range(num_runs):\n",
    "            start_time = time.time()\n",
    "            output_gpu = convolution_im2col(x_gpu, kernel_gpu, device='gpu')\n",
    "            end_time = time.time()\n",
    "            \n",
    "            gpu_time = end_time - start_time\n",
    "            gpu_times.append(gpu_time)\n",
    "            print(f\"Run {i+1}: {gpu_time:.4f} seconds\")\n",
    "        \n",
    "        avg_gpu_time = np.mean(gpu_times)\n",
    "        std_gpu_time = np.std(gpu_times)\n",
    "        print(f\"GPU Average: {avg_gpu_time:.4f} ± {std_gpu_time:.4f} seconds\")\n",
    "        print(f\"GPU Output shape: {output_gpu.shape}\\n\")\n",
    "        \n",
    "        # Speedup calculation\n",
    "        speedup = avg_cpu_time / avg_gpu_time\n",
    "        print(f\"=== Performance Comparison ===\")\n",
    "        print(f\"CPU Time: {avg_cpu_time:.4f} ± {std_cpu_time:.4f} seconds\")\n",
    "        print(f\"GPU Time: {avg_gpu_time:.4f} ± {std_gpu_time:.4f} seconds\")\n",
    "        print(f\"Speedup: {speedup:.2f}x {'faster on GPU' if speedup > 1 else 'faster on CPU'}\")\n",
    "        \n",
    "        # Verify results are similar (accounting for floating point precision)\n",
    "        try:\n",
    "            output_gpu_cpu = output_gpu.cpu()\n",
    "            max_diff = np.max(np.abs(output_cpu.data - output_gpu_cpu.data))\n",
    "            print(f\"Maximum difference between CPU and GPU results: {max_diff:.2e}\")\n",
    "            if max_diff < 1e-5:\n",
    "                print(\"✓ Results are numerically equivalent\")\n",
    "            else:\n",
    "                print(\"⚠ Results differ significantly\")\n",
    "        except Exception as e:\n",
    "            print(f\"Could not compare results: {e}\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"GPU benchmark failed: {e}\")\n",
    "        print(\"This might be because:\")\n",
    "        print(\"1. CuPy is not installed\")\n",
    "        print(\"2. No CUDA-compatible GPU is available\")\n",
    "        print(\"3. GPU memory is insufficient\")\n",
    "        \n",
    "    print(\"\\n=== Memory Usage Info ===\")\n",
    "    input_size_mb = x_data.nbytes / (1024**2)\n",
    "    kernel_size_mb = kernel_data.nbytes / (1024**2)\n",
    "    output_size_mb = (1 * 64 * 222 * 222 * 4) / (1024**2)  # 4 bytes per float32\n",
    "    \n",
    "    print(f\"Input tensor: {input_size_mb:.2f} MB\")\n",
    "    print(f\"Kernel tensor: {kernel_size_mb:.2f} MB\")\n",
    "    print(f\"Output tensor: {output_size_mb:.2f} MB\")\n",
    "    print(f\"Total memory usage: ~{input_size_mb + kernel_size_mb + output_size_mb:.2f} MB\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    benchmark_convolution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dfdde30",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from core.tensor import Tensor\n",
    "from core.nn import batchnorm2d\n",
    "\n",
    "# Create a random input tensor\n",
    "x = Tensor(np.random.rand(32, 64, 224, 224), requires_grad=True)\n",
    "# Create a batch normalization layer\n",
    "bn = batchnorm2d(64)\n",
    "\n",
    "# Forward pass\n",
    "y = bn(x)\n",
    "\n",
    "print(\"Output shape:\", y.shape)  # Should be (32, 64, 224, 224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ef02953",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from core.tensor import Tensor\n",
    "\n",
    "# Create a random input tensor\n",
    "x = Tensor(2)\n",
    "y = x**3\n",
    "y.backward()\n",
    "print(\"x:\", x.grad)  # Should be 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9e03d9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PyTorch\n",
    "from torch import nn\n",
    "from core.tensor import Tensor\n",
    "from core.nn import ConvBatchNorm2D\n",
    "import torch\n",
    "import numpy as np\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# Create test input for 2D CNN-like data\n",
    "x_np = np.random.randn(4, 8, 16, 16).astype(np.float32)\n",
    "x_torch = torch.tensor(x_np, dtype=torch.float32)\n",
    "\n",
    "\n",
    "bn = nn.BatchNorm2d(8, affine=True, track_running_stats=False)\n",
    "bn.weight.data.fill_(1.0)\n",
    "bn.bias.data.fill_(0.0)\n",
    "\n",
    "out_torch = bn(x_torch)\n",
    "\n",
    "# Your layer\n",
    "custom_bn = ConvBatchNorm2D(8)\n",
    "out_custom = custom_bn(Tensor(x_np)).data\n",
    "\n",
    "# Compare\n",
    "print(\"BatchNorm diff:\", np.abs(out_custom - out_torch.detach().numpy()).max())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "220cfd50",
   "metadata": {},
   "outputs": [],
   "source": [
    "from core.tensor import Tensor\n",
    "import numpy as np\n",
    "from core.nn import Linear\n",
    "# Create a random input tensor\n",
    "x = Tensor(np.random.rand(2,10,8), requires_grad=True)\n",
    "# Create a linear layer\n",
    "linear = Linear(input_dim=8, output_dim=16)\n",
    "\n",
    "# Forward pass\n",
    "y = linear(x)\n",
    "\n",
    "print(\"Output shape:\", y.shape)  # Should be (2, 16)\n",
    "# Forward pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29843edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from core.tensor import Tensor\n",
    "# Original tensor\n",
    "x_np = np.array([[1.0, 2.0, 3.0, 4.0, 5.0, 6.0]], dtype=np.float32)\n",
    "x_pt = torch.tensor(x_np, requires_grad=True)\n",
    "x_coco  = Tensor(x_np, requires_grad=True)\n",
    "\n",
    "# Split into 3 parts along axis=1\n",
    "splits = torch.tensor_split(x_pt, 3, dim=1)  # 3 tensors: (1,2), (1,2), (1,2)\n",
    "splits_coco = x_coco.split(indices_or_sections=3, axis=1)  # 3 tensors: (1,2), (1,2), (1,2)\n",
    "# Apply operations to trigger backward\n",
    "result = sum([s.sum() for s in splits])  # Just add all elements\n",
    "result_coco = sum([s.sum() for s in splits_coco])  # Just add all elements\n",
    "\n",
    "result.backward()\n",
    "result_coco.backward()\n",
    "\n",
    "# Check gradients\n",
    "\n",
    "print(\"Torch Grad:\", x_pt.grad.numpy())\n",
    "print(\"Coco Grad:\", x_coco.grad)\n",
    "print(\"Gradients match:\", np.allclose(x_pt.grad.numpy(), x_coco.grad.data))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43b1147f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from core.tensor import Tensor\n",
    "\n",
    "# Setup input\n",
    "x_np = np.array([[1., 2., 3., 4., 5., 6.]], dtype=np.float32)\n",
    "x_pt = torch.tensor(x_np, requires_grad=True)\n",
    "x_coco = Tensor(x_np, requires_grad=True)\n",
    "\n",
    "# Split into 3 parts along axis=1\n",
    "pt_splits = torch.tensor_split(x_pt, 3, dim=1)\n",
    "coco_splits = x_coco.split(indices_or_sections=3, axis=1)\n",
    "\n",
    "# Apply different operations to each part\n",
    "pt_result = pt_splits[0].sum() + (pt_splits[1] ** 2).sum() + (pt_splits[2] * 2).sum()\n",
    "coco_result = coco_splits[0].sum() + (coco_splits[1] ** 2).sum() + (coco_splits[2] * 2).sum()\n",
    "\n",
    "# Backward\n",
    "pt_result.backward()\n",
    "coco_result.backward()\n",
    "\n",
    "# Compare gradients\n",
    "print(\"Torch Grad:\", x_pt.grad.numpy())\n",
    "print(\"Coco Grad:\", x_coco.grad)\n",
    "print(\"Gradients match:\", np.allclose(x_pt.grad.numpy(), x_coco.grad.data, atol=1e-5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d04f93a",
   "metadata": {},
   "outputs": [],
   "source": [
    "coco_result.view_graph(filename=\"split_graph\", view=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "995d4434",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Match: True\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1462fc4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deeplearning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
